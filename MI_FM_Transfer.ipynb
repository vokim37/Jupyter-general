{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcgis, arcpy\n",
    "from arcgis.gis import GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_feature = r'Database Connections\\FIRS_Steward@maint.gissqlkc.sde\\maint.FIRS.d_flowmonitors_point_edit'\n",
    "related_table = r'Database Connections\\FIRS_Steward@maint.gissqlkc.sde\\maint.FIRS.t_flowmonitors_relatedrecords_edit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = open(\"C:\\\\Users\\\\kimvo\\\\OneDrive - King County\\\\Documents\\\\getpass.txt\").readline()\n",
    "gis = GIS(\"http://kingcounty.maps.arcgis.com/home\", \"kimvo_kingcounty\", password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = gis.content.search('title: METER','Feature Layer')[0]\n",
    "MIlayer = search.layers[0]\n",
    "MIdata = MIlayer.query().features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ago_fields = [\"METER_ID\",\"ID_FAC\",\"DEPTH_FAC\",\"PROJECT\",\"S_DATE\",\"HEIGHT\",\"WIDTH\",\"PIPE_SHAPE\",\\\n",
    "              \"MATERIAL\",\"REQUESTOR\",\"METER_TYPE\",\"SENSOR1\",\"SENSOR1_OFFSET\",\"SENSOR2\",\\\n",
    "              \"SENSOR2_OFFSET\",\"TRIPOD_REQUIRED\",\"SAFETY_TRAFFIC\",\"HYDRAULICS\",\"OTHER_INFO\",\\\n",
    "              \"SURCHARGE\",\"TIMEOFDATE\",\"DEPTH_OF_FLOW\",\"DEPTH_DEVIA\",\"VELOCITY\",\"SILT\",\"SILT_DEVIA\",\\\n",
    "              \"E_DATE\"]\n",
    "rt_fields = [\"METER_ID\",\"ID_FAC\",\"DEPTH_FAC\",\"PROJECT\",\"S_DATE\",\"HEIGHT\",\"WIDTH\",\"PIPE_SHAPE\",\\\n",
    "              \"MATERIAL\",\"REQUESTOR\",\"METER_TYPE\",\"SENSOR1\",\"SENSOR1_OFF\",\"SENSOR2\",\\\n",
    "              \"SENSOR2_OFF\",\"TRIPOD_REQ\",\"SAFE_TRAFF\",\"HYDROLICS\",\"OTHERINFO\",\\\n",
    "              \"SURCHARGE\",\"TIMEOFDAY\",\"DEPTH_FLOW\",\"DEPTH_DEVIATION\",\"VELOCITY\",\"SILT\", \"SILT_DEVIATION\",\\\n",
    "              \"E_DATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup saved for feature class: Q:\\WTD\\DataDev\\FlowMonitors\\Shapes\\Backups\\d_flowmonitors_point_edit_20190708.xml\n",
      "Backup saved for related table: Q:\\WTD\\DataDev\\FlowMonitors\\Shapes\\Backups\\t_flowmonitors_relatedrecords_edit_20190708.xml\n"
     ]
    }
   ],
   "source": [
    "# Backup fc and related table before doing editing\n",
    "loc = r'Q:\\WTD\\DataDev\\FlowMonitors\\Shapes\\Backups'\n",
    "date = str(datetime.datetime.now())[0:10].replace(\"-\", \"\") #20180524\n",
    "fcName = point_feature.split(\"\\\\\")[-1:][0].split(\".\")[-1:][0]\n",
    "tbName = related_table.split(\"\\\\\")[-1:][0].split(\".\")[-1:][0]\n",
    "\n",
    "fcOutput = loc + \"\\\\\" + fcName + \"_\" + date + \".xml\"\n",
    "arcpy.ExportXMLWorkspaceDocument_management(point_feature, fcOutput, \"DATA\", \"BINARY\", \"METADATA\")\n",
    "print(\"Backup saved for feature class:\", fcOutput)\n",
    "\n",
    "tbOutput = loc + \"\\\\\" + tbName + \"_\" + date + \".xml\"\n",
    "arcpy.ExportXMLWorkspaceDocument_management(related_table, tbOutput, \"DATA\", \"BINARY\", \"METADATA\")\n",
    "print(\"Backup saved for related table:\", tbOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, datetime\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "log_loc = r'\\\\dnrp1\\projects\\WTD\\DataDev\\FlowMonitors\\Documents\\MI_PostProcess_Logs'\n",
    "# set fields for insert cursor for feature class\n",
    "fc_fields = ['METER_ID', 'SHAPE@XY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "\n",
    "def convertXY(x1, y1):\n",
    "    inProj = Proj(init='EPSG:3857')\n",
    "    outProj = Proj(init='EPSG:2926')#32048 NAD27\n",
    "    x2,y2 = transform(inProj,outProj,x1,y1)\n",
    "    return (x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = \"Database Connections\\\\FIRS_Steward@maint.gissqlkc.sde\"\n",
    "edit = arcpy.da.Editor(arcpy.env.workspace)\n",
    "edit.startEditing(False, True)\n",
    "edit.startOperation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New point with new record\n",
    "f_cursor = arcpy.da.InsertCursor(point_feature, fc_fields)\n",
    "all_existing_meterID = [row[0] for row in arcpy.da.SearchCursor(point_feature, ['METER_ID'])]\n",
    "with open(log_loc + '\\\\Log_' + ts + '.csv', 'a', newline ='') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    # write header for csv log\n",
    "    filewriter.writerow(['New Meter with New Record'])\n",
    "    filewriter.writerow(rt_fields)\n",
    "    # look for new ACTIVE meter with new record\n",
    "    for i in MIdata:\n",
    "        if i.attributes['METER_ID'] not in all_existing_meterID and i.attributes['S_DATE'] is not None:\n",
    "            # insert shape and meter ID to fc\n",
    "            x = i.geometry['x']\n",
    "            y = i.geometry['y']\n",
    "            f_cursor.insertRow([i.attributes['METER_ID'], convertXY(x,y)])\n",
    "            del f_cursor\n",
    "            print('New active METER_ID:', i.attributes['METER_ID'])\n",
    "            # insert attributes to related table\n",
    "            value = []\n",
    "            t_cursor = arcpy.da.InsertCursor(related_table, rt_fields)\n",
    "            for a in ago_fields:\n",
    "                if type(i.attributes[a]) == str and \",\" in i.attributes[a]:\n",
    "                    i.attributes[a] = i.attributes[a].replace(\",\",' ')\n",
    "                if a == \"TIMEOFDATE\" or a == 'S_DATE':\n",
    "                    date_str = time.strftime('%m/%d/%Y %H:%M:%S', time.localtime((i.attributes[a])/1000.0))\n",
    "                    value.append(date_str)\n",
    "                else:\n",
    "                    value.append(i.attributes[a])\n",
    "            t_cursor.insertRow(value)\n",
    "            # write record to csv log\n",
    "            filewriter.writerow(value)\n",
    "            del t_cursor\n",
    "            print('Added attributes to related table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing location, new attributes/recors\n",
    "act_exiting_meterID = [row[0] for row in arcpy.da.SearchCursor(related_table, ['METER_ID'], \\\n",
    "                                                               where_clause = \"E_DATE IS NULL\")]\n",
    "t_cursor = arcpy.da.InsertCursor(related_table, rt_fields)\n",
    "with open(log_loc + '\\\\Log_' + ts + '.csv', 'a', newline ='') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    # write header for csv log\n",
    "    filewriter.writerow(['Historical Meter with New Record'])\n",
    "    filewriter.writerow(rt_fields)\n",
    "    # look for new meter with new record but have existing location in fc\n",
    "    for i in MIdata:\n",
    "        if i.attributes['METER_ID'] not in act_exiting_meterID \\\n",
    "        and i.attributes['METER_ID'] in all_existing_meterID \\\n",
    "        and i.attributes['E_DATE'] is None \\\n",
    "        and i.attributes['S_DATE'] is not None:\n",
    "            # insert attributes to related table\n",
    "            value = []\n",
    "            for a in ago_fields:\n",
    "                if type(i.attributes[a]) == str and \",\" in i.attributes[a]:\n",
    "                    i.attributes[a] = i.attributes[a].replace(\",\",' ')\n",
    "                if (a == \"TIMEOFDATE\" or a == 'S_DATE') and i.attributes[a] is not None:\n",
    "                    date_str = time.strftime('%m/%d/%Y %H:%M:%S', time.localtime((i.attributes[a])/1000.0))\n",
    "                    value.append(date_str)\n",
    "                else:\n",
    "                    value.append(i.attributes[a])\n",
    "            t_cursor.insertRow(value)\n",
    "            # write record to csv log\n",
    "            filewriter.writerow(value)\n",
    "            print('Added new attributes to related table for existing location:',i.attributes['METER_ID'])\n",
    "del t_cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added E_DATE for removed meter: RNT055\n",
      "Deleted feature from MI: RNT055\n"
     ]
    }
   ],
   "source": [
    "# current active meter got removed\n",
    "act_exiting_meterID = [row[0] for row in arcpy.da.SearchCursor(related_table, ['METER_ID'], \\\n",
    "                                                               where_clause = \"E_DATE IS NULL\")]\n",
    "with open(log_loc + '\\\\Log_' + ts + '.csv', 'a', newline ='') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    # write header for csv log\n",
    "    filewriter.writerow(['Current Active Meter got removed'])\n",
    "    filewriter.writerow(rt_fields)\n",
    "    # look for current active meter just got removed\n",
    "    for i in MIdata:\n",
    "        if i.attributes['METER_ID'] in act_exiting_meterID \\\n",
    "        and i.attributes['E_DATE'] is not None \\\n",
    "        and i.attributes['S_DATE'] is not None:\n",
    "            # insert attributes to related table\n",
    "            value = []\n",
    "            t_cursor = arcpy.da.InsertCursor(related_table, rt_fields)\n",
    "            for a in ago_fields:\n",
    "                if type(i.attributes[a]) == str and \",\" in i.attributes[a]:\n",
    "                    i.attributes[a] = i.attributes[a].replace(\",\",' ')\n",
    "                if (a == \"TIMEOFDATE\" or a == 'S_DATE' or a == 'E_DATE') and i.attributes[a] is not None:\n",
    "                    date_str = time.strftime('%m/%d/%Y %H:%M:%S', time.localtime((i.attributes[a])/1000.0))\n",
    "                    value.append(date_str)\n",
    "                else:\n",
    "                    value.append(i.attributes[a])\n",
    "            t_cursor.insertRow(value)\n",
    "            # write record to csv log\n",
    "            filewriter.writerow(value)\n",
    "            del t_cursor\n",
    "            print('Added E_DATE for removed meter:',i.attributes['METER_ID'] )\n",
    "            # delete removed meter in MI database\n",
    "            MIlayer.edit_features(deletes = str(i.attributes['FID']))\n",
    "            print('Deleted feature from MI:', str(i.attributes['METER_ID']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit.stopOperation()\n",
    "edit.stopEditing(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
